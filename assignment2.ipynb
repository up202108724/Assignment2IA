{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **Supervised Learning - Autism Dataset for Toddlers**\n",
    "\n",
    "## Autism Spectrum Disorder (ASD) Diagnosis\n",
    "\n",
    "# **Introduction**\n",
    "\n",
    "# The Dataset being used is adapted from the Kaggle's Autism Dataset for Toddlers page, which contains 1054 reported cases , each with 19 attributes. The most important ones to look at is, namely, the Q-chat-score, that is , the aggregate of the results from the 10-question questionaire, that corresponds to influential features to be utilised for further analysis especially in determining autistic traits , each one corresponding also to an binary attribute, and other labeled attributes, such as Sex,Ethnicity,Jaundice,Family_mem_with_ASD,Who completed the test, and the \"Class/ASD Traits \", which is derived from the Q-Chat Score. The remaining one that is numeric , is the case numeber, a unique identifier for each row of results\n",
    "\n",
    "# The goal of this project is to improve the classification of the ASD traits, given a whole dataset of diagnosis based on certain features evaluated on the questionnaires, and evaluate their distribution by other parallel factors that are labeled, such as Sex,Ethnicity,Jaundice,Family_mem_with_ASD,Who completed the test, and the \"Class/ASD Traits \"\n",
    "\n",
    "# The solution to this problem is a supervised learning model, which will be trained using the dataset mentioned above. The model will be trained using the training set, and then evaluated using the test set. The model will be evaluated using the accuracy metric, which is the percentage of diagnosis that are correctly done / probability of a certain diagnose is correctly done , taking into account all the labeled factors.\n",
    "\n",
    "---\n",
    "\n",
    "This project was made possible by:\n",
    "\n",
    "| Name | Email |\n",
    "|-|-|\n",
    "| André Silva | up202108724@up.pt |\n",
    "| Bernardo Pinto | up202108842@up.pt |\n",
    "| Francisco Sousa | up202108838@up.pt |\n",
    "|---|---|\n",
    "| Group | T10 - G104 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c313b65565e4764",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "Throughout the study, many libraries were incrementally added, thus, it is important to install them all, which can be done by running the following command in the terminal (make sure you are in the project's root directory):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Then, we can import the libraries we will use in this project.\n",
    "\n",
    "Note that we also had disabled the warnings, to make the notebook cleaner."
   ]
  },
  {
   "cell_type": "code",
   "id": "2efb324116429092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:14:53.413062Z",
     "start_time": "2024-05-26T21:14:53.409334Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stat\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier # não está a funcionar, por agora\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "#import pycaret\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "ade5bc09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T21:14:53.455279Z",
     "start_time": "2024-05-26T21:14:53.446063Z"
    }
   },
   "source": [
    "#import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv(\"./Autism_dataset.csv\")\n",
    "dataframe.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
       "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
       "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
       "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
       "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
       "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
       "\n",
       "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
       "0   f  middle eastern      yes                  no          family member   \n",
       "1   m  White European      yes                  no          family member   \n",
       "2   m  middle eastern      yes                  no          family member   \n",
       "3   m        Hispanic       no                  no          family member   \n",
       "4   f  White European       no                 yes          family member   \n",
       "\n",
       "  Class/ASD Traits  \n",
       "0               No  \n",
       "1              Yes  \n",
       "2              Yes  \n",
       "3              Yes  \n",
       "4              Yes  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_No</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>Age_Mons</th>\n",
       "      <th>Qchat-10-Score</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Family_mem_with_ASD</th>\n",
       "      <th>Who completed the test</th>\n",
       "      <th>Class/ASD Traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>f</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>White European</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>m</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>f</td>\n",
       "      <td>White European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>family member</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data pre-processing\n",
    "\n",
    "## Pre analysis\n",
    "\n",
    "The first step is to analyze the dataset, to understand its structure and the type of data it contains. This will allow us to identify any missing values outliers, or other issues that need to be addressed before training the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bed32f41ac62ee9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataframe.describe()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51ae46ff2b0bab71"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataframe.isna().any()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cffd39d5d9f24119"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataframe= dataframe.drop(columns=['Case_No','Qchat-10-Score'])\n",
    "print(dataframe['Class/ASD Traits'].head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2706f18f8093e593"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "encoder= LabelEncoder()\n",
    "\n",
    "binary_cols= [\"Sex\", \"Jaundice\", \"Family_mem_with_ASD\" , \"Class/ASD Traits\"]\n",
    "\n",
    "for binary_atribute in binary_cols:\n",
    "    dataframe[binary_atribute] = encoder.fit_transform(dataframe[binary_atribute])\n",
    "\n",
    "dataframe[\"Who completed the test\"]= dataframe[\"Who completed the test\"].replace(\"Health care professional\",\"Health Care Professional\")\n",
    "\n",
    "#print(dataframe[\"Who completed the test\"].unique())\n",
    "\n",
    "categorical_cols = [\"Ethnicity\", \"Who completed the test\"]\n",
    "\n",
    "\n",
    "# Applying one-hot encoding to categorical columns\n",
    "one_hot_encoded = pd.get_dummies(dataframe[categorical_cols])\n",
    "\n",
    "# Concatenating one-hot encoded columns with the original dataframe\n",
    "dataframe_encoded = pd.concat([dataframe, one_hot_encoded], axis=1)\n",
    "\n",
    "# Dropping the original categorical columns\n",
    "dataframe_encoded.drop(categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Displaying the resulting dataframe\n",
    "#np.unique(dataframe_encoded.iloc[:,17:18])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39b93481839f2b4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Analysis\n",
    "\n",
    "We can now analyze the dataset to better understand the distribution of the data and the relationships between the different features. This will help us identify any patterns or trends that may be useful for training the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6301c999dda743b8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Assuming dataframe_encoded is your dataframe after one-hot encoding\n",
    "\n",
    "# Splitting the dataframe based on the target variable\n",
    "df1 = dataframe_encoded[dataframe_encoded['Class/ASD Traits'] == 1].drop(columns=['Class/ASD Traits'])\n",
    "df2 = dataframe_encoded[dataframe_encoded['Class/ASD Traits'] == 0].drop(columns=['Class/ASD Traits'])\n",
    "print(dataframe_encoded.columns)\n",
    "\n",
    "# Plotting the distributions\n",
    "num_columns = len(df1.columns)\n",
    "plot_index = 1\n",
    "\n",
    "for i in range(num_columns):\n",
    "    column_name = df1.columns[i]\n",
    "    plt.subplot(6, 6, plot_index)\n",
    "    \n",
    "    if column_name == 'Age_Mons':\n",
    "        continue\n",
    "    else:\n",
    "        # Count occurrences of 0s and 1s\n",
    "        count_0_1_df1 = df1[column_name].value_counts().sort_index()\n",
    "        count_0_1_df2 = df2[column_name].value_counts().sort_index()\n",
    "        \n",
    "        # Create a DataFrame for plotting\n",
    "        plot_data = pd.DataFrame({\n",
    "            'Value': [0, 1],\n",
    "            'ASD': count_0_1_df1,\n",
    "            'Non-ASD': count_0_1_df2\n",
    "        }).fillna(0)  # Fill NaNs with 0\n",
    "        \n",
    "        # Plot bars\n",
    "        bar_width = 0.35\n",
    "        plt.bar(plot_data['Value'] - bar_width/2, plot_data['ASD'], width=bar_width, label='ASD', color='blue', alpha=0.7)\n",
    "        plt.bar(plot_data['Value'] + bar_width/2, plot_data['Non-ASD'], width=bar_width, label='Non-ASD', color='orange', alpha=0.7)\n",
    "        plt.xlabel(column_name)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks([0, 1])\n",
    "    \n",
    "    plt.legend()\n",
    "    plot_index += 1\n",
    "\n",
    "\n",
    "# Special plot for continuous variable 'age-months'\n",
    "df1['Group'] = 'ASD'\n",
    "df2['Group'] = 'Non-ASD'\n",
    "df = pd.concat([df1, df2])\n",
    "        \n",
    "\n",
    "binwidth = 1\n",
    "age_min = int(df['Age_Mons'].min())\n",
    "age_max = int(df['Age_Mons'].max()) + binwidth\n",
    "bins = range(age_min, age_max, binwidth)\n",
    "df['Age_Binned'] = pd.cut(df['Age_Mons'], bins, right=False, include_lowest=True)\n",
    "# Count occurrences within each bin and group\n",
    "count_df = df.groupby(['Age_Binned', 'Group']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 6))\n",
    "count_df.plot(kind='bar', width=0.8, color=['blue', 'orange'])\n",
    "plt.xlabel('Age (Months)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Age Distribution by ASD and Non-ASD Groups')\n",
    "plt.legend(title='Group')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "df1.drop(columns=['Group'], inplace=True)\n",
    "df2.drop(columns=['Group'], inplace=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea6b89a08b948215"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cramers_v(x, y):\n",
    "    \"\"\"Calculate Cramér's V statistic for categorical-categorical association.\"\"\"\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = stat.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    return np.sqrt(chi2 / (n * (min(confusion_matrix.shape) - 1)))\n",
    "\n",
    "def calculate_correlations(dataframe, target_column):\n",
    "    correlations = {}\n",
    "    for column in dataframe.columns:\n",
    "        if column == target_column:\n",
    "            continue\n",
    "        if column==\"Age_Mons\":\n",
    "            corr = stat.pointbiserialr(dataframe[target_column], dataframe[column])[0]\n",
    "        else:\n",
    "            corr = cramers_v(dataframe[column], dataframe[target_column])    \n",
    "        correlations[column] = corr\n",
    "    return correlations\n",
    "# a_function(int a.bar(), bool b.foo())\n",
    "# Assuming dataframe_encoded is your dataframe\n",
    "target_column = 'Class/ASD Traits'\n",
    "\n",
    "for column in dataframe.columns:\n",
    "    if dataframe[column].dtype == 'object':\n",
    "        dataframe[column] = encoder.fit_transform(dataframe[column])\n",
    "\n",
    "#print(before_one_hot[\"Ethnicity\"])\n",
    "\n",
    "# Check if the target column is in the dataframe's columns\n",
    "\n",
    "if target_column in dataframe.columns:\n",
    "    # Calculate correlations\n",
    "    correlations = calculate_correlations(dataframe, target_column)\n",
    "    \n",
    "    # Convert to DataFrame for heatmap\n",
    "    correlation_df = pd.DataFrame.from_dict(correlations, orient='index', columns=[target_column])\n",
    "    correlation_df = correlation_df.sort_values(by=target_column, ascending=False)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.title(f'Correlations with {target_column}')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{target_column}' not found in the dataframe.\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bfe3d0d498977b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "84e4bc565c414b8e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "def calculatecorrelations_columns(dataframe,leftColumn, rightColumn):\n",
    "    if dataframe[leftColumn].nunique() == 2:  # Binary\n",
    "        if dataframe[rightColumn].nunique() == 2:\n",
    "            # Both are binary -> Cramér's V\n",
    "            #print(\"Cramers_v : \" + leftColumn + rightColumn )\n",
    "            corr = cramers_v(dataframe[leftColumn], dataframe[rightColumn])\n",
    "        else:\n",
    "            # Binary - Continuous -> Point Biserial\n",
    "            #print(\"Point Biserial Continuous/Binary : \" + leftColumn + rightColumn)\n",
    "            corr, _ = stat.pointbiserialr(dataframe[leftColumn], dataframe[rightColumn])\n",
    "    elif dataframe[rightColumn].nunique() == 2:\n",
    "        # Continuous - Binary -> Point Biserial\n",
    "        #print(\"Point Biserial Binary(Continuous : \" + leftColumn + rightColumn)\n",
    "        corr, _ = stat.pointbiserialr(dataframe[rightColumn], dataframe[leftColumn])\n",
    "    else:\n",
    "        # Continuous - Continuous -> Pearson's\n",
    "        #print(\"Pearson's : \" + leftColumn + rightColumn)\n",
    "        corr = dataframe[leftColumn].corr(dataframe[rightColumn]) # Nunca entra aqui, pois o dataset só tem uma coluna continua\n",
    "    return corr\n",
    "'''\n",
    "def calculatecorrelations_notencodedcolumns(dataframe,leftColumn, rightColumn):\n",
    "    \n",
    "    if (leftColumn==\"Age_Mons\" and rightColumn==\"Ethnicity\") or (leftColumn==\"Ethnicity\" and rightColumn==\"Age_Mons\"):\n",
    "        grouped_data = [dataframe[dataframe[\"Ethnicity\"] == category][\"Age_Mons\"] for category in dataframe[\"Ethnicity\"].unique()]\n",
    "        f_stat, p_value = stat.f_oneway(*grouped_data)\n",
    "        corr = p_value # Mudar o algoritmo talvez\n",
    "    elif (leftColumn==\"Age_Mons\" and rightColumn==\"Who completed the test\") or (leftColumn==\"Who completed the test\" and rightColumn==\"Age_Mons\"):\n",
    "        grouped_data = [dataframe[dataframe[\"Who completed the test\"] == category][\"Age_Mons\"] for category in dataframe[\"Who completed the test\"].unique()]\n",
    "        f_stat, p_value = stat.f_oneway(*grouped_data)\n",
    "        corr = p_value # Mudar o algoritmo talvez\n",
    "    elif ((leftColumn==\"Age_Mons\"  and dataframe[rightColumn].nunique() == 2 ) or (rightColumn==\"Age_Mons\" and dataframe[leftColumn].nunique() == 2 ) ):\n",
    "         if leftColumn==\"Age_Mons\":\n",
    "            corr = stat.pointbiserialr(dataframe[rightColumn], dataframe[leftColumn])[0]\n",
    "         else:\n",
    "            corr = stat.pointbiserialr(dataframe[leftColumn], dataframe[rightColumn])[0]    \n",
    "    else:\n",
    "        corr = cramers_v(dataframe[leftColumn], dataframe[rightColumn])         \n",
    "    return corr\n",
    "higher_correlation = []\n",
    "correlations_values = []\n",
    "df_columns = dataframe.columns\n",
    "\n",
    "for i, col1 in enumerate(df_columns):\n",
    "    if col1 == 'Class/ASD Traits':\n",
    "        continue\n",
    "    for col2 in df_columns[i::]:\n",
    "        if col1 == col2 or col2 == 'Class/ASD Traits':\n",
    "            continue\n",
    "        a_corr= calculatecorrelations_notencodedcolumns(dataframe,col1, col2)\n",
    "        if a_corr > 0.8:    \n",
    "            print(f\"Correlation between {col1} and {col2}: {a_corr} \\n\")\n",
    "        correlations_values.append(a_corr)\n",
    "#print(sorted(correlations_values))\n",
    "#print(len(correlations_values))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffd48231a57508b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa60b1f2a4f82881"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "features = dataframe.drop(['Class/ASD Traits'],axis=1)\n",
    "labels = dataframe['Class/ASD Traits']\n",
    "\n",
    "np.unique(labels, return_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f69067017a334fb5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "smote_enn = SMOTE(random_state=42)\n",
    "x_train, y_train = smote_enn.fit_resample(x_train, y_train)\n",
    "print(np.unique(y_train, return_counts=True))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "282b4f402c96110d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "classifiers.append([\"Decision tree classifier\",DecisionTreeClassifier()])\n",
    "classifiers.append([\"KNeighbors Classifier\",KNeighborsClassifier()])\n",
    "classifiers.append([\"SVM\",SVC()])\n",
    "classifiers.append([\"Random Forest\",RandomForestClassifier()])\n",
    "classifiers.append([\"Gradient Boosting\",GradientBoostingClassifier()])\n",
    "\n",
    "accuracy_scores = {}\n",
    "precision_scores = {}\n",
    "recall_scores = {}\n",
    "f1_scores = {}\n",
    "confusion_matrices = {}\n",
    "training_times = {}\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(x_test)\n",
    "    \n",
    "    training_times[name] = time.time() - start_time\n",
    "    \n",
    "    accuracy_scores[name] = accuracy_score(y_test, y_pred)\n",
    "    precision_scores[name] = precision_score(y_test, y_pred)\n",
    "    recall_scores[name] = recall_score(y_test, y_pred)\n",
    "    f1_scores[name] = f1_score(y_test, y_pred)\n",
    "    confusion_matrices[name] = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "for clf_name, clf in classifiers:\n",
    "    print(f\"Classifier: {clf_name}\")\n",
    "    print(f\"Accuracy: {accuracy_scores[clf_name]}\")\n",
    "    print(f\"Precision: {precision_scores[clf_name]}\")\n",
    "    print(f\"Recall: {recall_scores[clf_name]}\")\n",
    "    print(f\"F1 Score: {f1_scores[clf_name]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[clf_name]}\")\n",
    "    print(f\"Training Time: {training_times[clf_name]} seconds\")\n",
    "    print(\"----------------------------------------\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af4c35ae2904f6e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
